

\chapter{Work}
\label{chap:work}
% **************************** Define Graphics Path **************************
\ifpdf
    \graphicspath{{Chapter3/Figs/Raster/}{Chapter3/Figs/PDF/}{Chapter3/Figs/}}
\else
    \graphicspath{{Chapter3/Figs/Vector/}{Chapter3/Figs/}}
\fi

The aim of this study was to capture the iterative elongation process
of even-chain saturated Fatty Acids. Fatty Acids are
carboxylic acids with long hydrocarbon side groups
(Figure~\ref{fig:fas}) and they are usually characterised by the
number of carbons in these side-groups, for example a FA with a chain
of 6 carbons is usually denoted as $C_6$. The side-chains of FAs grow
by successive $C_2$ concatenations. This concatenation process takes places at
the FA biosynthesis pathway in the cytosol for chain lengths up to
$C_{18}$. Further elongation takes places at the FA elongation
pathway in the Endoplasmatic Reticulum(ER).

\begin{figure}[htbp!]
\centering
\includegraphics[width=0.6\textwidth]{fas}
\caption[Fatty Acid structure]{The structure of Fatty Acids(FA) which
  consists of a long hydrocarbon side-group. The length of this
  side-group charactersises the FA.}
\label{fig:fas}
\end{figure}

In this study we are interested in the elongation process in its
entirety so our models capture the combined effect of the two pathways
responsible for it, FA biosynthesis \textit{and} FA elongation. In
this section I first introduce the basic model and the assumptions
made to simplify it, the tuning of that basic model based on FA
measurements, a version of the model in stochastic pi-calculus and
finally the extension of the model with the introduction of some
control mechanisms.

\section{Basic model}
\subsection{Petri Net implementation}
FA biosynthesis starts with Acetyl-CoA which is being converted to
Malonyl-CoA. A reaction between Malonyl-CoA and Acetyl-CoA starts off
the first $C_4$ FA product. After that there are successive $C_2$
concatenations to elongate the FA product with each elongation step
, that requires 4 reactions, requiring another Malonyl-CoA(Figure~\ref{fig:fa_synthesis}). The
full pathway from KEGG can be seen in
Figure~\ref{fig:kegg_synthesis}. The elongation pathway located in ER
is similar in nature but the intermediaries are CoAs instead of
ACPs(Figure \ref{fig:kegg_elongation}).

\begin{figure}[htbp!]
\centering
\includegraphics[width=1.0\textwidth]{fa_metabolism}
\caption[FA metabolism]{FA metabolism in relation to other pathways.}
\label{fig:fa_synthesis}
\end{figure}

\begin{figure}[htbp!]
\centering
\includegraphics[width=1.0\textwidth]{kegg_synthesis}
\caption[Fatty Acid biosynthsis in cytosol]{FA biosynthesis in the
  cytosol. Notice the successive concatenations. Each concatenation
  takes 4 reactions.}
\label{fig:kegg_synthesis}
\end{figure}

\begin{figure}[htbp!]
\centering
\includegraphics[width=0.3\textwidth]{kegg_elongation}
\caption[Fatty Acid elongation in ER]{General form of FA elongation in
ER. Notice that the intermediate products are CoAs instead of ACPs as
in biosynthesis.}
\label{fig:kegg_elongation}
\end{figure}

Because of the natural correspondence between biochemical reactions as
they are found in the KEGG static model to Petri Net model constructs
a straight translation between the two is straightforward. All the
pathway reactions become transitions with pre-places the reactants and
post-places the products. Here we made our first assumptions by
omitting the enzymes from the reactions. Information about the enzymes
is not so important for our purposes since we are interested in the
numbers of molecules of the metabolites in the system. Information
about the enzymes can be incorporated in the transition rates.
The net can be animated using its formal
operational semantics and as transitions/reactions occur
tokens/metabolites move through the net. The FA products are
represented as sinks, places that are not pre-places to any
transitions, so once a token reaches one of these sinks it is
trapped. That way the probabilistic iterative nature of the process is
capture completely, an intermediate of the process can either remain
at that length or go on to form longer FAs. The sinks are therefore
the outputs of the stochastic process with the inputs being the places
that do not act as post-places for any transitions. Starting with some
finite number of molecules at the inputs, these will be consumed
throughout the process until we reach a dead-state where no further
transitions are enabled. The translation from the KEGG pathway model
to the Petri Net model was done manually with the SNOOPY \cite []
{heiner2012snoopy}tool which
allows you to draw a net and play the token game for basic nets to
observe its behaviour.

\begin{figure}[htbp!]
\centering
\includegraphics[width=1.0\textwidth]{pn_fa_elongation}
\caption[FA elongation Petri Net model]{}
\label{fig:pn_fa_elongation}
\end{figure}

A direct translation from KEGG is certainly useful for capturing a
low-level biochemical view of the system. The model can offer an even
more fine-control view of the system than the model presented in
Figure~\ref{fig:pn_fa_elongation} by including the enzymes in the
reactions and information about their affinity to the reaction
substrates. However including too many details in the model can
sometimes hide the true aspect of the system the modeller is trying to
understand and analyse. Here we are interested in the probabilistic,
non-deterministic nature of the iterative FA elongation process which
happens as this series of $C_2$ concatenation steps in FA elongation
and biosynthesis pathways in ER and cytosol respectively. The outputs
we are particularly interested to see are the numbers and proportions of FAs at
different lengths. In Petri Nets model language these are the number
and more importantly the proportions
of molecules/tokens that end up in the sink places at the stop of the model
execution. Because the process is inherently iterative and
probabilistic these numbers will be different at the end of each model
execution. This is in contrast with most dynamic modelling approaches
as we are not interested in the time traces but rather only at the end
result of this stochastic process. We can think of the Petri Net as a
magic box governed by some probabilities(that we can tune) where we
throw some inputs and according to these probabilities some output
will come out at the other end in the form of proportions of FAs at different
lengths. The probabilities are just the control parameters that guide
the operation of the magic box.

Having outlined our modelling goals in the previous section we can now
make some assumptions that will guide our design of the simplified
synthesis/elongation model that will be our basic model throughout
this study. First of all the model will capture the combined effect of
both the pathways. The two pathways are in different compartments of
the cell, one in cytosol and one in ER, but we will ignore the
transportation of FAs from cytosol to ER and we will assume that the
two process are sequential so a $C_{18}$ for example can be elongated
directly to a $C_{20}$ while in reality it would have to first be
transported to the ER. Since we also take this view of the
net model as a control box turning input signal through a series of
steps to an output signal we can safely squeeze the four step reaction chain
needed for each $C_2$ concatenation step to a single step reaction and
at the same time consider only the forward direction
reactions. Also, since we are no longer consider exact chemical
reactions the reactions rate functions will just be constant values
and we will treat those more as probabilities that will govern the
non-deterministic decisions during the execution of the model that
transforms the input signal to output proportions of FAs. Finally I
also decided to stop the elongation process at $C_{22}$ and that the
sinks will only include products $C_{12}$ - $C_{22}$. FAs with lengths
4-10 will be included but no output will be accumulated there. These
decisions are a bit arbitrary but they are ultimately tied with the
output real datasets I had available for tuning the model(see
subsequent sections).

To build the basic model then that follows from the goals and this
assumptions was built manually with SNOOPY \cite [] {heiner2012snoopy}. This basic model that will
be the basis for our work in this study can be seen in
Figure~\ref{fig:fa_elongation_full}. The model is similar in nature to
the more full model presented previously but the concatenation steps
are represented as single transitions and the elongation process goes
up to $C_{22}$ because the elongation process in the ER is also
included. Starting simple I also started from the inputs Malonyl-CoA
and Acetyl-CoA whereas in reality the only precursor of FA
biosynthesis is Acetyl-CoA and the 2 input points of the pathway are
products coming from Acetyl-CoA. The model as presented in
Figure~\ref{fig:fa_elongation_full} starts with inputs: 300
Malonyl-CoA and 100 Acetyl-CoA molecules. The model can then be set in
motion with SNOOPY until it reaches a dead state which basically
corresponds to the point where the system runs out of input
metabolites to 'fuel' any further reactions. The output of the system
is the number of tokens accumulated at each of the sinks or FAs of
different lengths.

\begin{figure}[htbp!]
\centering
\includegraphics[width=1.0\textwidth]{fa_elongation_full}
\caption[Petri Net implementation(basic model)]{Petri Net
  implementation of the basic model as described in the main text}
\label{fig:fa_elongation_full}
\end{figure}


Observing the execution pattern of the basic net model we notice an
execution pattern which leads to an elegant view of the system as a
series of binary probabilistic decisions or Bernoulli trials. The way
the inputs of the model are set up, at the start of the model
execution only the initial transition producing the first product $C_4$ is
enabled. If we consider that after this transition fires (since its
the only one enabled) it
will only fire again after its initial product has reached a sink then
at each point only one token is travelling through the net. This token
goes through an iteration of binary decisions: stay at current length
\textit{or} continue to form a longer
FA. More formally as the token gets
transformed to an intermediate product there are only two transitions
enabled: the transition taking it to the next longer intermediate and
the transition taking to be stored at its current length(Figure~\ref{fig:binary_decision}). Let these
two transitions be $t_1$ and $t_2$ respectively. According to
the operational semantics of Stochatic Petri Nets(see Methods section)
a wait time is sampled for each of the enabled transitions from a
negative exponential distribution with rate the value of the rate
function of the
transition. In this case the rate function of the two transitions are
constants(see assumptions) $\lambda_{t_1}$ and $\lambda_{t_2}$. Since
we know that one of the reactions will fire we can say that the
firing probabilities of the two transitions or the probabilities of
the token's decisions are:

\begin{align*}
P(staying)& =P(t_1) = \frac{\lambda_{t_1}}{\lambda_{t_1} + \lambda_{t_2}}\\
P(continuing) & = P(t_2) = \frac{\lambda_{t_2}}{\lambda_{t_1} + \lambda_{t_2}} = 1 - P(t_1)\\
\end{align*}


\begin{figure}[htbp!]
\centering
\includegraphics[width=0.5\textwidth]{binary_decision}
\caption[Binary stay-continue decision]{Binary decision at a
  particular point in the execution.}
\label{fig:binary_decision}
\end{figure}

In other words this is a Bernoulli trial with probability of success
$p = P(t_1)$. Since we only care about the outputs at the end of the
execution and not the timeframe of the process from start to finish
then only the ratio of these two successive transitions rates is
important and not their absolute numbers. Then the entire journey of a token through the network
from the initial $C_4$ product until it reaches a sink and gets stored
can be thought of a series of Bernoulli
trials(Figure~\ref{fig:trials}). Then the entire stochastic process
can be thought of a sequence of successive realisations of this series
of trials with tokens travelling through the net one
after the other with each one going through the series of decisions
or Bernoulli trials. The initial assumption that only one token
travels through the net at each time can in fact be dropped since the
output of the net only depends on the ratios of the pair of
transitions representing each binary decision. I just chose to have it
because this leads to the nice picture of the successive realisations
of chains of Bernoulli trials which is intuitive for illustration
purposes.
It is also interesting to note how this binary decision
corresponds to a conflict between two events that share pre-conditions
which create non-determinsim through a race condition between the two
depdendent events. This 'conflict' which represents this decision
process is captured inherently in the structure and semantics of Petri
Nets.

\begin{figure}[htbp!]
\centering
\includegraphics[width=0.55\textwidth]{trials}
\caption[Stochastic proces as a series of Bernoulli trials]{The entire
stochastic process a series of Bernoulli trials.}
\label{fig:trials}
\end{figure}

Each realisation of the stochastic process described by the Petri Net
model which is itself a series of successive realisations of series of
Bernoulli trials will have different outputs. While SNOOPY is a great
tool for the visual side of things, creating the model and animating
them, in order to be able to execute the model many times to get
output profiles we needed a programmatic solution. I wrote code in
Python that can read a model, execute it once or many times, and write
out the results. For the description of the model I used the PySCeS
model description language for biochemical systems which is aimed at
the Python language. The reactions are
defined in the standard chemical notation and since this corresponds
exactly to Petri Net transitions it was easy to load the description
into an appropriate Petri Net representation(Figure~\ref{fig:code}).

\begin{figure}[htbp!]
\centering
\includegraphics[width=1.0\textwidth]{code}
\caption[Workflow]{Structure of the code and workflow}
\label{fig:code}
\end{figure}


\subsection{Model parameters}
In the previous section I described the building of the basic model
based on the goals and assumptions of the study. The elongation aspect
that we are interested in was reduced down to a sequence of successive
series of Bernoulli trials that determine the length that a FA will
stop its elongation at. The interesting parameters of the model, the
ones that will affect the output, are the success probabilities for
the stay-continue decisions for FA intermediaries with lengths
$[C_{12}, C_{22}]$ since they are ones that have sinks. In this
section two methods for the identification of these parameters for
tuning the model so that its execution is biologically valid are
presented. They both rely on experimental data from an MS study that
contains relative MS spectra intensities for a number of lipid
products extracted from cells. The aim of the study for which the
experiment was conducted was to identify the effect of some treatment
in lipid products so it included 90 samples from control and treatment
(at different levels) individuals. Here we are only interested in creating a null
model so only the 30 samples from the control individuals in the
experiment were retained for
the purposes of parameter tuning.

The outputs of the net model are integer number of tokens accumulated
at each of the sinks or FA of different lengths while the experimental
data are relative intensities which are continuous numbers. In order
to be able to compare the two for the tuning of the parameters the
experimental data were transformed from relative intensities to
relative absolute numbers. The transormation of a sample of relative
intensities $\mathbf{s} = \{s_1, s_2, s_3, s_4, s_5, s_6\}$ became a
transformed sample $\mathbf{ts} = \{ ts_i | ts_i = \lfloor s_i /
min(\mathbf{s}) \rfloor \}$.
 Since we are only interested in the
relative proportions of the outputs going from relative intensities to
relative numbers should not affect the outcome. The data can then be
seen as different realisations of the stochastic process described by
the real model that acts in nature. The attempt is then to tune our
model to be as close to the real model as possible by trying to tune
the proportions of the outputs of our model to match the proportions
of the outputs by the real model represented in the experimental
data. This is  classical Machine Learning formulation of the inverse
problem(Figure~\ref{fig:ml}). In this section I first present a method to get point
estimates and then profiles for the success probabilities parameters of the series of Bernoulli
trials representing the chain of decisions for a token travelling
through the net.

\begin{figure}[htbp!]
\centering
\includegraphics[width=0.5\textwidth]{ml}
\caption[ML inverse problem formulation]{ML inverse problem formulation}
\label{fig:ml}
\end{figure}



\subsubsection{Point estimates}
The data more formally are a matrix $D$ with an element $D_{ik}$ being
the number of tokens accumulated in the $k$-th FA in the $i$-th
sample or realisation of the process. Since we have multiple
realisations of Bernoulli trials the success probabilities can also be
though of as success probabilities in binomial distributions. The
Maximum Likelihood point estimator for binomial success probabilities
is given for the $i$-th decision corresponding to the $i$-th FA,
\begin{equation*}
\hat{p_i} = \frac{k_i}{n_i}
\end{equation*}
, where $k_i$ is the number of successes and $n_i$ is the number of
trials. If we extract information about the number of successes and
number of trials for each binary decision in the process from the data
that are different realisation of the process then we can
straightforwardly compute the success probabilities we are after.

If we a take a specific sample (a row from data matrix $D$) then the
number of successes for an FA are simply just the number of tokens of
that FA in the sample since those are the tokens that when faced with
the decision of whether to get stored as that FA or continue to form
longer FAs they chose the former. Success and failure are arbitrarily
assigned to staying and continuing respectively. The number of trials
is the number of all the tokens that reached that FA intermediary, both
the ones that stayed \textit{and} the ones that continued. Since this
is an iterative process the ones that continued are the number of
tokens that made it to the sinks after the FA(the ones on the right as
we look at the Petri Net model picture,
Figure~\ref{fig:pn_elongation_full}). To illustrate this consider a
sample which could be a row from our data matrix $D$: $\{C_{12}=5,
C_{14}=10, C_{16}=34, C_{18}=23, C_{20}=3, C_{22}=5\}$. The ML
estimator for the $i$-th FA product in that sample will be:
\begin{equation*}
\hat{p_i} = \frac{C_i}{\sum_{n \geq i} C_n}
\end{equation*}
The success probabilities $p_1$ to $p_6$ for the above sample, with $p_1$ corresponding to
the first binary decision and $C_{12}$, $p_s$ to the second decision
and $C_{14}$ and so on, are:
\begin{align*}
\hat{p_1} & = 5/(5+10+34+23+3+5) = 0.0625\\
\hat{p_2} & = 10 / (10+34+23+3+5) = 0.1333\\
\hat{p_3} & = 34 / (34+23+3+5) = 0.523\\
\hat{p_4} & = 23 / (23+3+5) = 0.742\\
\hat{p_5} & = 3 / (3+5) = 0.375\\
\hat{p_6} & = 1
\end{align*}
This is for one sample but since all the samples are from the same
population(controls) we can combine the successes/trials data from all
samples and generalise the ML success probability estimation for the
$i$-th FA products as:
\begin{equation*}
\hat{p_i} = \frac{\sum_k D_{ki}}{\sum_k \sum_{n\geq i} D_{kn}}
\end{equation*}
We assume that the columns of data matrix D are ordered according to
the order of FAs in the system.

Computing the success probabilities from the real experimental dataset
can be seen in Table~\ref{tab:param_estimates}.

\begin{table}
\centering
    \begin{tabular}{ccc}
    Parameter & Value \\
    $p_1$ &  0.0003000656 \\
    $p_2$ & 0.0400323889\\
    $p_3$ &  0.8235217126\\
    $p_4$ &  0.9888339514\\
    $p_5$ &  0.778597786 \\
    $p_6$ &  1.0
    \end{tabular}
\label{tab:param_estimates}
\end{table}
Since
we do not care about the timeframe of the process but rather at the
output at the end the relative proportions of the transitions
participating in a binary decision are what is important therefore we
can use the calculated success probabilities as the rates of the
transitions related to the binary decision. So for example since
$\hat{p_3}\approx0.82$ then the rates of the transitions corresponding to the
binary decision for the 3rd FA, $C_{16}$, will be: rate of transition
for $C_{16}$ storage (success) $0.82$ and rate of transition for
$C_{18}$ formation (failure) $0.18$($1-P(success)$).


\subsubsection{Profiles}
In the previous section I derived point estimates for the success
probabilities guiding the binary decisions taking place during the
elongation process. I did that by considering the success
probabilities that maximise the likelihood function $L(D|p_i)$ for
the $i$-th FA and data $D$ being the number of successes and number of
trials. In this section I will present a likelihood function for the
entire process which comes naturally by thinking of the process as
before as a sequence of series of Bernoulli trials. I then use this
likelihood function to get the profiles of the parameters of interest.


The data from one of the samples can be seen as one realisation of the
stochastic process with the numbers of tokens at each FA being the
outputs of the series of Bernoulli trials that make up one realisation
of the entire process. Each series of Bernoulli trials describes the
journey of one token through the net which ends when it finds a
sink. If for example the token ends up at the third sink that means
that the outcome of the series of Bernoulli trials was: fail, fail,
success. Therefore the data consisting of the number of tokens that
ended up at each FA gives us a history of the series of trials that
happened during that realisation of the process. Consider the
following sample $\{C_{12}=5, C_{14}=10, C_{16}=34, C_{18}=23,
C_{20}=3, C_{22}=5\}$ which is one realisation of the process from
the start until reaching a dead-state. The numbers tell us the 'fate'
of each of the tokens that went through the net during that
realisation of the process, 5 tokens made the decision to stay at the
first trial- [success]- , 10 tokens made a decision to continue on the
first decision and then to stay on the second decision- [fail,
sucess]-, 34 tokens continued on the first two decision and stayed on
the third- [fail, fail, success], and so on. We can therefore calculate
the probabilities for each FA product sinks as follows:
\begin{align}
P(C_{12}) &= p_1 \nonumber\\
P(C_{14}) &= (1-p_1)p_2 \nonumber\\
P(C_{16}) &= (1-p_1)(1-p_2)p_3 \nonumber \\
P(C_{18}) &= (1-p_1)(1-p_2)(1-p_3)p_4 \nonumber\\
P(C_{20}) &= (1-p_1)(1-p_2)(1-p_3)(1-p_4)p_5 \nonumber\\
P(C_{22}) &= (1-p_1)(1-p_2)(1-p_3)(1-p_4)(1-p_5)p_6 \nonumber\\
\label{eq:param_cor}
\end{align}
The entire process can then be seen as a multinomial draw with 6
outcomes,  $\{C_{12}, C_{14}, C_{16}, C_{18}, C_{20}, C_{22}\}$, with
their respective probabilities given above and with the number of
trials being the number of tokens that ended up in sinks for that
particular realisation of the process. This gives the likelihood
function of the data given the success probabilities as
probability mass function of the multinomial distribution:
\begin{equation*}
L(D|\mathbf{\theta}) = f(C_{12},\dots, C_{22}; n ; P(C_{12}), \dots,
P(C_{22})\}) =
\end{equation*}

Using the likelihood function for the entire process we can find the
posterior of the initial success probabilities $p_1$ to $p_6$,
\begin{equation*}
P(\{p_i\} | D) \sim L(D | \{p_i\}) P(\{p_i\})
\end{equation*}
where the data $D$ is simply the outputs of one realisation of the
process or the counts at each sink and $P(\{p_i\})$ are the priors of
the parameters. If we assume uniformative priors the above parameter
posterior simply becomes: $P(\{p_i\} | D) \sim L(D | \{p_i\})$. Since
the parameters are not exactly the parameters of the multinomial but
they are only related through Equations~\ref{eq:param_cor} an analytic
solutions is not very attractive but since it is still a small problem
we can resort to a simple simulation scheme to sample from the required
posterior. I used the standard Metropolis-Hastings MCMC method to
sample from the posterior as given above starting from a random point
in parameter space and a symmetric normal proposal distribution with
mean the previous accepted guess and an arbitrary chosen variance. The
MCMC traces and the histograms of the samples obtained from the
posteriors can be seen in Figure.


\subsection{A stochastic $\pi$-calculus implementation}
In this section I present a stochastic pi-calculus version of the
model which is specifically written in its SPiM variant which extends
the traditional pi-calculus first by introducing explicitly time which
is needed for quantitive analysis of biochemical networks and also by
adding operational semantics in terms of an Abstract Machine and a
graphical representation language. The SPiM code is given for the
processes making up the system to introduce further some of the
concepts of the SPiM language. For more information about the SPiM
language.

The SPiM graphcal representation of the model can be seen in
Figure~\ref{fig:spim_graph}. Each component of that graph is a
stochastic pi-calculus process and edges between them indicate that
one one of them can evolve into the other. The nature of the model is
different from the equivalent model given in the previous section. The
evolution of every species represented by a stochastic pi-calculus
process is defined independently. We start the computation by running 100
\texttt{Acyl_CoA} processes and 30 \texttt{Malonyl_CoA} processes:

\begin{verbatim}
run(100 of Malonyl_CoA() | 30 of Acyl_CoA())
\end{verbatim}

The initial reaction of the system creating is represented as
communication by channell \texttt{form6} between \texttt{Acyl_CoA} and
\texttt{Malonyl_CoA} processes. Once the communication happens the
\texttt{Acyl_CoA} process evolves into the  \texttt{Acyl_CoA_4}
process while \texttt{Malonyl_CoA} process goes to the empty
process(gets consumed). After that all the processes corresponding
FAs between $C_6$ and $C_{10}$ only have one communication option,
communicate via the appropriate channell with a \texttt{Malonyl_CoA}
process and then evolve into a process corresponding to a longer
FA. For example process \texttt{Acyl_CoA_8}:

\begin{verbatim}
and Acyl_CoA_8() = ?form10; Acyl_CoA_10()
\end{verbatim}

After that all the processes corresponding to intermediaries for longer
than $C_{10}$ FAs have two communication options corresponding to the familiar
stay-continue stochastic decision that we have seen in the previous section, they
can either communicate with a \texttt{Malonyl_CoA} process and evolve
into a process corresponding to a longer FA while the
\texttt{Malonyl_CoA} process terminates or do a delay and evolve into
their corresponding FA product. The FA products which are modelled as
empty processes could have been ignored since they do not interact
further with any other processes but they were kept there
intentionally to keep track of their numbers.

\begin{figure}[htbp!]
\centering
\includegraphics[width=1.0\textwidth]{spim_graph}
\caption[SPiM graph]{SPiM graph}
\label{fig:spim_graph}
\end{figure}

\begin{verbatim}
let Malonyl_CoA() =
(
	do !form6; ()
	or !form8; ()
	or !form10; ()
	or !form12; ()
	or !form14; ()
	or !form16; ()
)
and Acyl_CoA() = ?form6; Acyl_CoA_6()
and Acyl_CoA_6() = ?form8; Acyl_CoA_8()
and Acyl_CoA_8() = ?form10; Acyl_CoA_10()
and Acyl_CoA_10() = ?form12; Acyl_CoA_12()
and Acyl_CoA_12() =
(
	do ?form14; Acyl_CoA_14()
	or delay@store_rate_12; C12()
)
and Acyl_CoA_14() =
(
	do ?form16; Acyl_CoA_16()
	or delay@store_rate_14; C14()
)
and Acyl_CoA_16() =
(
	do ?form18; Acyl_CoA_18()
	or delay@store_rate_16; C16()
)
and Acyl_CoA_18() =
(
	do ?form20; Acyl_CoA_20()
	or delay@store_rate_18; C18()
)
and Acyl_CoA_20() =
(
	do ?form22; Acyl_CoA_22()
	or delay@store_rate_20; C20()
)
and Acyl_CoA_22() = delay@store_rate_22; C22()
and C12() = ()
and C14() = ()
and C16() = ()
and C18() = ()
and C20() = ()
and C22() = ()

run(100 of Malonyl_CoA() | 30 of Acyl_CoA())
\end{verbatim}






\section{Extended model of FA synthesis}

\subsection{Petri Net implementation}



\subsection{Model Parameters}

